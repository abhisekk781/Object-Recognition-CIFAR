{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near State-of-the-Art results at Object Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U keras tensorflow\n",
    "#Update Keras\n",
    "\n",
    "#Clear SSL Certification Issues\n",
    "import os\n",
    "import os.path\n",
    "import ssl\n",
    "import stat\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "STAT_0o775 = ( stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR\n",
    "             | stat.S_IRGRP | stat.S_IWGRP | stat.S_IXGRP\n",
    "             | stat.S_IROTH |                stat.S_IXOTH )\n",
    "\n",
    "\n",
    "def main():\n",
    "    openssl_dir, openssl_cafile = os.path.split(\n",
    "        ssl.get_default_verify_paths().openssl_cafile)\n",
    "\n",
    "    import certifi\n",
    "    # change working directory to the default SSL directory\n",
    "    os.chdir(openssl_dir)\n",
    "    relpath_to_certifi_cafile = os.path.relpath(certifi.where())\n",
    "    print(\" -- removing any existing file or link\")\n",
    "    try:\n",
    "        os.remove(openssl_cafile)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    print(\" -- creating symlink to certifi certificate bundle\")\n",
    "    os.symlink(relpath_to_certifi_cafile, openssl_cafile)\n",
    "    print(\" -- setting permissions\")\n",
    "    os.chmod(openssl_cafile, STAT_0o775)\n",
    "    print(\" -- update complete\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load necessary packages\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the dataset\n",
    "\n",
    "First things first, we need to preprocess the dataset so the images and labels are in a form that Keras can ingest. To start, we'll define a NumPy seed for reproducibility, then normalize the images. \n",
    "\n",
    "Furthermore, we will also convert our class labels to one-hot vectors.  This is a standard output format for neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a convolutional neural network for object recognition on CIFAR-10\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 6\n",
    "np.random.seed(seed) \n",
    "\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "# normalize the inputs from 0-255 to 0.0-1.0\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n",
      "[6]\n"
     ]
    }
   ],
   "source": [
    "# class labels shape\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class labels are a single integer value (0-9).  What we really want is a one-hot vector of length ten.  For example, the class label of 6 should be denoted [0, 0, 0, 0, 0, 0, 1, 0, 0, 0].  We can accomplish this using the np_utils.to_categorical() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# hot encode outputs\n",
    "Y_train = np_utils.to_categorical(y_train)\n",
    "Y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = Y_test.shape[1]\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Building the All-CNN\n",
    "\n",
    "Using the paper as a reference, we can implement the All-CNN network in Keras.  Keras models are built by simply adding layers, one after another. \n",
    "\n",
    "To make things easier for us later, we will wrap this model in a function, which will allow us to quickly and neatly generate the model later on in the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start building the model - import necessary layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Activation, Conv2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def allcnn(weights=None):\n",
    "    # define model type - Sequential\n",
    "    model = Sequential()\n",
    "\n",
    "    # add model layers - Convolution2D, Activation, Dropout\n",
    "    model.add(Conv2D(96, (3, 3), padding = 'same', input_shape=(32, 32, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(96, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(96, (3, 3), padding = 'same', strides = (2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same', strides = (2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Conv2D(192, (3, 3), padding = 'same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192, (1, 1), padding = 'valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(10, (1, 1), padding = 'valid'))\n",
    "\n",
    "    # add GlobalAveragePooling2D layer with Softmax activation\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # load the weights\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    \n",
    "    # return model\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Defining Parameters and Training the Model\n",
    "\n",
    "We're all set! We are ready to start training our network.  In the following cells, we will define our hyper parameters, such as learning rate and momentum, define an optimizer, compile the model, and fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_37 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/350\n",
      "24800/50000 [=============>................] - ETA: 8:54 - loss: 2.0694 - accuracy: 0.2160"
     ]
    }
   ],
   "source": [
    "# define hyper parameters\n",
    "learning_rate = 0.01\n",
    "weight_decay = 1e-6\n",
    "momentum = 0.9\n",
    "\n",
    "# build model \n",
    "model = allcnn()\n",
    "\n",
    "# define optimizer and compile model\n",
    "sgd = SGD(lr=learning_rate, decay=weight_decay, momentum=momentum, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "# print model summary\n",
    "print (model.summary())\n",
    "\n",
    "# define additional training parameters\n",
    "epochs = 350\n",
    "batch_size = 32\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=epochs, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model accuracy\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Making Predictions\n",
    "\n",
    "Using the pretrained weights, we were able to achieve an accuracy of nearly 90 percent! Let's leverage this network to make some predictions. To start, we will generate a dictionary of class labels and names by referencing the website for the CIFAR-10 dataset:\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "Next, we'll make predictions on nine images and compare the results to the ground-truth labels.  Furthermore, we will plot the images for visual reference, this is object recognition after all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary of class labels and names\n",
    "classes = range(0,10)\n",
    "\n",
    "names = ['airplane',\n",
    "        'automobile',\n",
    "        'bird',\n",
    "        'cat',\n",
    "        'deer',\n",
    "        'dog',\n",
    "        'frog',\n",
    "        'horse',\n",
    "        'ship',\n",
    "        'truck']\n",
    "\n",
    "# zip the names and classes to make a dictionary of class_labels\n",
    "class_labels = dict(zip(classes, names))\n",
    "\n",
    "# generate batch of 9 images to predict\n",
    "batch = X_test[100:109]\n",
    "labels = np.argmax(Y_test[100:109],axis=-1)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(batch, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print our predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are individual class probabilities, should sum to 1.0 (100%)\n",
    "for image in predictions:\n",
    "    print(np.sum(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use np.argmax() to convert class probabilities to class labels\n",
    "class_result = np.argmax(predictions,axis=-1)\n",
    "print class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a grid of 3x3 images\n",
    "fig, axs = plt.subplots(3, 3, figsize = (15, 6))\n",
    "fig.subplots_adjust(hspace = 1)\n",
    "axs = axs.flatten()\n",
    "\n",
    "for i, img in enumerate(batch):\n",
    "\n",
    "    # determine label for each prediction, set title\n",
    "    for key, value in class_labels.items():\n",
    "        if class_result[i] == key:\n",
    "            title = 'Prediction: {}\\nActual: {}'.format(class_labels[key], class_labels[labels[i]])\n",
    "            axs[i].set_title(title)\n",
    "            axs[i].axes.get_xaxis().set_visible(False)\n",
    "            axs[i].axes.get_yaxis().set_visible(False)\n",
    "            \n",
    "    # plot the image\n",
    "    axs[i].imshow(img.transpose([1,2,0]))\n",
    "    \n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
